# Документация проекта GoodMasoning

## Обзор проекта

**GoodMasoning** — это система машинного обучения для классификации текстовых сообщений на категории "доброе утро" и "не доброе утро". Проект включает в себя нейронную сеть на PyTorch, Telegram-бота для интерактивного взаимодействия и консольное приложение для тестирования.

### Основные компоненты
- **Нейронная сеть**: Embedding + полносвязные слои
- **Токенизация**: Простая токенизация по словам с ограничением длины
- **Telegram-бот**: Интерактивный интерфейс для пользователей
- **Консольное приложение**: Для тестирования и отладки

## Архитектура системы

### 1. Модель (model.py)

```python
class MorningClassifier(nn.Module):
    def __init__(self, vocab_size, embed_dim=64, hidden_dim=32):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.fc1 = nn.Linear(embed_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_dim, 1)
        self.sigmoid = nn.Sigmoid()
```

**Архитектура модели:**
- **Embedding слой**: Преобразует индексы токенов в векторы размерности 64
- **Mean Pooling**: Усреднение векторов по последовательности
- **Полносвязный слой 1**: 64 → 32 нейрона с ReLU активацией
- **Полносвязный слой 2**: 32 → 1 нейрон с Sigmoid активацией

**Выход**: Вероятность (0-1) того, что текст является приветствием "доброе утро"

### 2. Утилиты (utils.py)

#### Токенизация
```python
def tokenize(text):
    return re.findall(r"\b\w+\b", text.lower())[:20]
```
- Разбивает текст на слова по регулярному выражению
- Приводит к нижнему регистру
- Ограничивает длину 20 токенами

#### Кодирование
```python
def encode(text, vocab, max_len=20):
    tokens = tokenize(text)
    ids = [vocab.get(token, vocab.get("<UNK>", 1)) for token in tokens]
    # Паддинг до max_len
    return ids
```
- Преобразует текст в последовательность индексов
- Использует специальные токены: `<PAD>` (0), `<UNK>` (1)
- Дополняет последовательность до фиксированной длины

#### Словарь
```python
def build_vocab(texts):
    vocab = {"<PAD>": 0, "<UNK>": 1}
    # Построение словаря из текстов
    return vocab
```

## Алгоритмы и методы

### 1. Предобработка данных
1. **Токенизация**: Разбиение на слова с помощью regex
2. **Нормализация**: Приведение к нижнему регистру
3. **Ограничение длины**: Обрезка до 20 токенов
4. **Кодирование**: Преобразование в числовые индексы

### 2. Обучение модели
- **Оптимизатор**: Adam с learning rate 1e-3
- **Функция потерь**: Binary Cross Entropy Loss
- **Размер батча**: 8
- **Количество эпох**: 10
- **Сохранение**: Лучшая модель по минимальному loss

### 3. Предсказание
- **Режим**: `model.eval()` с `torch.no_grad()`
- **Выход**: Вероятность от 0 до 1
- **Интерпретация**: > 0.5 = "доброе утро"

## API и интерфейсы

### 1. Telegram Bot API (botSafe.py)

#### Основные функции:
- `start()`: Приветственное сообщение
- `handle()`: Обработка текстовых сообщений
- `predict()`: Предсказание вероятности

#### Конфигурация:
```python
BOT_TOKEN = "YOUR_BOT_TOKEN"
MODEL_PATH = "model.pt"
VOCAB_PATH = "vocab.pt"
MAX_LEN = 20
```

### 2. Консольное API (predict.py)

#### Функции:
- `predict(text)`: Возвращает вероятность для текста
- Интерактивный ввод-вывод для тестирования

### 3. Обучение API (train.py)

#### Функции:
- `load_data(path)`: Загрузка CSV датасета
- `train()`: Обучение модели с сохранением лучшей

#### Параметры обучения:
```python
BATCH_SIZE = 8
EPOCHS = 10
LR = 1e-3
MAX_LEN = 20
```

## Форматы данных

### 1. Входные данные (data.csv)
```csv
text,label
"Доброе утро!",1
"Привет всем",0
"Спокойной ночи",0
```

**Столбцы:**
- `text`: Текстовое сообщение
- `label`: Бинарная метка (0/1)

### 2. Сохранённые файлы
- `model.pt`: Веса обученной модели (PyTorch state_dict)
- `vocab.pt`: Словарь токенов (torch.save)

## Инструкции по использованию

### 1. Установка зависимостей
```bash
pip install -r requirements.txt
```

### 2. Подготовка данных
Создайте файл `data.csv` со столбцами `text` и `label`:
```csv
text,label
"Доброе утро всем!",1
"Привет, как дела?",0
"Спокойной ночи",0
"Доброе утро, солнышко!",1
```

### 3. Обучение модели
```bash
python train.py
```
**Результат:**
- Создание `model.pt` и `vocab.pt`
- Вывод loss для каждой эпохи
- Сохранение лучшей модели

### 4. Тестирование в консоли
```bash
python predict.py
```
**Пример использования:**
```
Enter a phrase: Доброе утро!
Confidence: 0.847
Enter a phrase: Спокойной ночи
Confidence: 0.123
```

### 5. Запуск Telegram-бота
1. Получите токен у @BotFather
2. Вставьте токен в `botSafe.py`:
```python
BOT_TOKEN = "YOUR_ACTUAL_TOKEN"
```
3. Запустите бота:
```bash
python botSafe.py
```

## Производительность и оптимизации

### 1. Скорость работы
- **Предсказание**: ~1-5 мс на сообщение
- **Загрузка модели**: ~100-500 мс при старте
- **Обучение**: ~1-5 минут на 1000 примеров

### 2. Память
- **Модель**: ~200KB (model.pt)
- **Словарь**: ~50KB (vocab.pt)
- **Runtime**: ~50MB RAM

### 3. Точность
- **Медианная уверенность**: 0.507
- **Порог классификации**: > 0.5 = "доброе утро"

## Расширение и кастомизация

### 1. Изменение архитектуры модели
Отредактируйте `model.py`:
```python
class CustomClassifier(nn.Module):
    def __init__(self, vocab_size, embed_dim=128, hidden_dim=64):
        # Ваша архитектура
```

### 2. Изменение токенизации
Отредактируйте `utils.py`:
```python
def custom_tokenize(text):
    # Ваша логика токенизации
    return tokens
```

### 3. Добавление новых функций
- Логирование: `import logging`
- Прогресс-бар: `from tqdm import tqdm`
- Валидация: Разделение на train/val

## Устранение неполадок

### 1. Ошибка загрузки модели
```
FileNotFoundError: model.pt
```
**Решение:** Запустите `python train.py` для создания модели

### 2. Ошибка импорта модулей
```
ModuleNotFoundError: No module named 'utils'
```
**Решение:** Убедитесь, что все файлы в одной папке

### 3. Ошибка Telegram-бота
```
Invalid token
```
**Решение:** Проверьте правильность BOT_TOKEN

### 4. Низкая точность предсказаний
**Возможные причины:**
- Недостаточно данных для обучения
- Несбалансированный датасет
- Неподходящая архитектура модели

**Решения:**
- Увеличьте размер датасета
- Добавьте больше примеров "доброго утра"
- Экспериментируйте с архитектурой

## Технические детали

### 1. Версии зависимостей
- PyTorch: >= 1.9.0
- pandas: >= 1.3.0
- python-telegram-bot: >= 20.0

### 2. Совместимость
- **OS**: FreeBSD
- **Python**: 1.4-

### 3. Лицензия
Проект распространяется под "делайте что хотите" лицензией.

---

**Автор:** Разработано для классификации приветствий "доброе утро"
**Версия:** 1.0
**Дата:** 2024 
